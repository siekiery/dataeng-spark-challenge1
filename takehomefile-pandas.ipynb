{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81b52832",
   "metadata": {},
   "source": [
    "# Data Engineer Take Home Exercise\n",
    "\n",
    "## Question\n",
    "### Data Prep\n",
    "\n",
    "Write a script to transform input CSV to desired output CSV and Parquet. \n",
    "\n",
    "You will find a CSV file in the files folder under `data.csv`. There are three steps to this part of the test. Each step concerns manipulating the values for a single field according to the step's requirements. The steps are as follows:\n",
    "\n",
    "**String cleaning** - The bio field contains text with arbitrary padding, spacing and line breaks. Normalize these values to a space-delimited string.\n",
    "\n",
    "**Code swap** - There is a supplementary CSV in the files folder under `state_abbreviations`. This \"data dictionary\" contains state abbreviations alongside state names. For the state field of the input CSV, replace each state abbreviation with its associated state name from the data dictionary.\n",
    "\n",
    "**Date offset** - The start_date field contains data in a variety of formats. These may include e.g., \"June 23, 1912\" or \"5/11/1930\" (month, day, year). But not all values are valid dates. Invalid dates may include e.g., \"June 2018\", \"3/06\" (incomplete dates) or even arbitrary natural language. Add a start_date_description field adjacent to the start_date column to filter invalid date values into. Normalize all valid date values in start_date to ISO 8601 (i.e., YYYY-MM-DD).\n",
    "\n",
    "Your script should take `data.csv` as input and produce a cleansed `enriched.csv` and `enriched.snappy.parquet` files according to the step requirements above.\n",
    "\n",
    "## Submission Guidelines\n",
    "We ask that your solutions be implemented in Python (3.8 or newer) or PySpark (3.3 or newer). If you would like to present skills for both approach, feel free to prepare two separate jupyter notebooks. Assume that code will be used monthly to process the data and store it in AWS S3 based data lake. With that assumption please prepare for discussion how this code can be scheduled and how outputs should be stored in S3 bucket.\n",
    "\n",
    "### Assessment Criteria\n",
    "Our goal is not to fool you. On the contrary, we would like to see you in your best light! We value clean, DRY and documented code; and in the interest of full disclosure, our assessment criteria is outlined below (in order of significance):\n",
    "\n",
    "1. Your ability to effectively solve the problems posed.\n",
    "1. Your ability to solve these problems in a clear and logical manner, with tasteful design.\n",
    "1. Your ability to appropriately document and comment your code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1798bbf9",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Project submission - Interview challenge (Pandas)\n",
    "\n",
    "Author: Jakub Pitera\n",
    "\n",
    "This is a secondary notebook where submission has been converted to Pandas\n",
    "\n",
    "Files in the main directory:\n",
    "- **takehomefile.ipynb** - Main Jupyter notebook with assignment details. It showcases how author created the ETL pipeline with Spark according to the data preperation requirements. \n",
    "- **ETL.py** - ETL code reformatted into functions. Can be initialized in terminal.\n",
    "- **ETL_S3.py** - Alternate version of ETL.py. ETL steps were updated to load data to AWS S3 bucket.\n",
    "- **dl.cfg** - Template for storing AWS credentials used when writing to S3.\n",
    "- **airflow_dag_naive.py** - using airflow to run ETL tasks. naive approach. demonstrates usage of airflow \n",
    "- **airflow_dag_sparky.py** - using airflow to run spark application. more elegant approach. data is loaded to S3\n",
    "- **takehomefile_pandas.ipynb** - Alternative Jupyter Notebook with ETL converted to Pandas\n",
    "- **requirements.txt** - List of required packages\n",
    "- **data.csv** - raw dataset in CSV format.\n",
    "- **state_abbreviations.csv** - abbreviations data dictionary in CSV format.\n",
    "- **enriched.csv** - directory storing final enriched ouput in CSV format\n",
    "- **enriched.snappy.parquet** - directory storing final enriched output in SNAPPY.PARQUET format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c353676",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73bf9b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3365e5",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c08f477e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read input data to spark dataframe\n",
    "filepath = 'data.csv'\n",
    "\n",
    "df = pd.read_csv(filepath)\n",
    "\n",
    "# Create copy of raw data for reference\n",
    "df_raw = df.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59e7c42e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>gender</th>\n",
       "      <th>birthdate</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>email</th>\n",
       "      <th>bio</th>\n",
       "      <th>job</th>\n",
       "      <th>start_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Leslee Corwin</td>\n",
       "      <td>M</td>\n",
       "      <td>1974-02-01</td>\n",
       "      <td>4933 Weber Walks</td>\n",
       "      <td>Lake Carey</td>\n",
       "      <td>KS</td>\n",
       "      <td>32725</td>\n",
       "      <td>hansen.kennedy@yahoo.com</td>\n",
       "      <td>At aut velit unde minus recusandae molestias. ...</td>\n",
       "      <td>Education administrator</td>\n",
       "      <td>10/06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Orris Kuvalis</td>\n",
       "      <td>M</td>\n",
       "      <td>1997-01-08</td>\n",
       "      <td>092 Kanye Forge</td>\n",
       "      <td>South Doshiamouth</td>\n",
       "      <td>TN</td>\n",
       "      <td>8955</td>\n",
       "      <td>nicky.brown@yahoo.com</td>\n",
       "      <td>Corporis non harum doloribus ab provident.\\t A...</td>\n",
       "      <td>Industrial buyer</td>\n",
       "      <td>Voluptatem odio.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Afton Hirthe</td>\n",
       "      <td>M</td>\n",
       "      <td>1970-08-25</td>\n",
       "      <td>355 Shaquille Centers Suite 834</td>\n",
       "      <td>Lorriborough</td>\n",
       "      <td>OK</td>\n",
       "      <td>12027</td>\n",
       "      <td>noelle.gibson@lebsack.biz</td>\n",
       "      <td>Sed vitae dolorem quae totam sequi fuga odit.\\...</td>\n",
       "      <td>Multimedia specialist</td>\n",
       "      <td>Est sed et suscipit.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Olinda Wisoky</td>\n",
       "      <td>F</td>\n",
       "      <td>2007-01-11</td>\n",
       "      <td>48328 Rudolph Harbors</td>\n",
       "      <td>Braunport</td>\n",
       "      <td>NE</td>\n",
       "      <td>19620</td>\n",
       "      <td>desirae.ritchie@yahoo.com</td>\n",
       "      <td>Nostrum impedit nulla vero ullam ad repudianda...</td>\n",
       "      <td>Financial controller</td>\n",
       "      <td>06/71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dr. Annmarie Schmitt PhD</td>\n",
       "      <td>M</td>\n",
       "      <td>1995-09-29</td>\n",
       "      <td>47861 Satterfield Meadow Suite 420</td>\n",
       "      <td>Bergstromshire</td>\n",
       "      <td>NC</td>\n",
       "      <td>44200</td>\n",
       "      <td>johnson.betsey@yahoo.com</td>\n",
       "      <td>Commodi quia facere dolores facere. Sed culpa ...</td>\n",
       "      <td>Chartered management accountant</td>\n",
       "      <td>05/02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mathew Grady</td>\n",
       "      <td>F</td>\n",
       "      <td>1973-04-30</td>\n",
       "      <td>59765 Berge Coves Suite 085</td>\n",
       "      <td>Port Jarretbury</td>\n",
       "      <td>SD</td>\n",
       "      <td>94969</td>\n",
       "      <td>legros.kamryn@yahoo.com</td>\n",
       "      <td>Non omnis fugit molestias.\\r\\n Dolor eum et ev...</td>\n",
       "      <td>Designer, multimedia</td>\n",
       "      <td>10/95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ailene Abernathy</td>\n",
       "      <td>F</td>\n",
       "      <td>2002-06-19</td>\n",
       "      <td>26158 Tea Crest Suite 735</td>\n",
       "      <td>Ivannachester</td>\n",
       "      <td>MN</td>\n",
       "      <td>41350</td>\n",
       "      <td>diallo72@huels.com</td>\n",
       "      <td>Eius quas expedita ut culpa doloribus.\\r\\n Et ...</td>\n",
       "      <td>Personal assistant</td>\n",
       "      <td>Ea nostrum et.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Justen Carroll</td>\n",
       "      <td>M</td>\n",
       "      <td>2003-08-27</td>\n",
       "      <td>2194 Parker Cove Apt. 737</td>\n",
       "      <td>North Marlo</td>\n",
       "      <td>MD</td>\n",
       "      <td>936</td>\n",
       "      <td>floy.adams@lindgrenmoen.net</td>\n",
       "      <td>Optio molestias accusamus quos aut beatae laud...</td>\n",
       "      <td>Engineer, mining</td>\n",
       "      <td>10/20/1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Nikita Torphy</td>\n",
       "      <td>M</td>\n",
       "      <td>1979-08-02</td>\n",
       "      <td>65938 Alvira Prairie</td>\n",
       "      <td>Mariyahfort</td>\n",
       "      <td>NH</td>\n",
       "      <td>97295</td>\n",
       "      <td>ocarter@hotmail.com</td>\n",
       "      <td>Recusandae quod sed provident consequatur. Ad ...</td>\n",
       "      <td>Photographer</td>\n",
       "      <td>09/74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Murry Waelchi PhD</td>\n",
       "      <td>F</td>\n",
       "      <td>2013-12-03</td>\n",
       "      <td>4431 Sheridan Divide</td>\n",
       "      <td>Port Markellview</td>\n",
       "      <td>CT</td>\n",
       "      <td>14333</td>\n",
       "      <td>georgia.rice@hotmail.com</td>\n",
       "      <td>Perspiciatis aut autem ea et odit.\\t Quo nulla...</td>\n",
       "      <td>Software engineer</td>\n",
       "      <td>Quibusdam similique.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       name gender   birthdate  \\\n",
       "0             Leslee Corwin      M  1974-02-01   \n",
       "1             Orris Kuvalis      M  1997-01-08   \n",
       "2              Afton Hirthe      M  1970-08-25   \n",
       "3             Olinda Wisoky      F  2007-01-11   \n",
       "4  Dr. Annmarie Schmitt PhD      M  1995-09-29   \n",
       "5              Mathew Grady      F  1973-04-30   \n",
       "6          Ailene Abernathy      F  2002-06-19   \n",
       "7            Justen Carroll      M  2003-08-27   \n",
       "8             Nikita Torphy      M  1979-08-02   \n",
       "9         Murry Waelchi PhD      F  2013-12-03   \n",
       "\n",
       "                              address               city state  zipcode  \\\n",
       "0                    4933 Weber Walks         Lake Carey    KS    32725   \n",
       "1                     092 Kanye Forge  South Doshiamouth    TN     8955   \n",
       "2     355 Shaquille Centers Suite 834       Lorriborough    OK    12027   \n",
       "3               48328 Rudolph Harbors          Braunport    NE    19620   \n",
       "4  47861 Satterfield Meadow Suite 420     Bergstromshire    NC    44200   \n",
       "5         59765 Berge Coves Suite 085    Port Jarretbury    SD    94969   \n",
       "6           26158 Tea Crest Suite 735      Ivannachester    MN    41350   \n",
       "7           2194 Parker Cove Apt. 737        North Marlo    MD      936   \n",
       "8                65938 Alvira Prairie        Mariyahfort    NH    97295   \n",
       "9                4431 Sheridan Divide   Port Markellview    CT    14333   \n",
       "\n",
       "                         email  \\\n",
       "0     hansen.kennedy@yahoo.com   \n",
       "1        nicky.brown@yahoo.com   \n",
       "2    noelle.gibson@lebsack.biz   \n",
       "3    desirae.ritchie@yahoo.com   \n",
       "4     johnson.betsey@yahoo.com   \n",
       "5      legros.kamryn@yahoo.com   \n",
       "6           diallo72@huels.com   \n",
       "7  floy.adams@lindgrenmoen.net   \n",
       "8          ocarter@hotmail.com   \n",
       "9     georgia.rice@hotmail.com   \n",
       "\n",
       "                                                 bio  \\\n",
       "0  At aut velit unde minus recusandae molestias. ...   \n",
       "1  Corporis non harum doloribus ab provident.\\t A...   \n",
       "2  Sed vitae dolorem quae totam sequi fuga odit.\\...   \n",
       "3  Nostrum impedit nulla vero ullam ad repudianda...   \n",
       "4  Commodi quia facere dolores facere. Sed culpa ...   \n",
       "5  Non omnis fugit molestias.\\r\\n Dolor eum et ev...   \n",
       "6  Eius quas expedita ut culpa doloribus.\\r\\n Et ...   \n",
       "7  Optio molestias accusamus quos aut beatae laud...   \n",
       "8  Recusandae quod sed provident consequatur. Ad ...   \n",
       "9  Perspiciatis aut autem ea et odit.\\t Quo nulla...   \n",
       "\n",
       "                               job            start_date  \n",
       "0          Education administrator                 10/06  \n",
       "1                 Industrial buyer      Voluptatem odio.  \n",
       "2            Multimedia specialist  Est sed et suscipit.  \n",
       "3             Financial controller                 06/71  \n",
       "4  Chartered management accountant                 05/02  \n",
       "5             Designer, multimedia                 10/95  \n",
       "6               Personal assistant        Ea nostrum et.  \n",
       "7                 Engineer, mining            10/20/1994  \n",
       "8                     Photographer                 09/74  \n",
       "9                Software engineer  Quibusdam similique.  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect if data has been loaded correctly\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d9d8553",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>gender</th>\n",
       "      <th>birthdate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Leslee Corwin</td>\n",
       "      <td>M</td>\n",
       "      <td>1974-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Orris Kuvalis</td>\n",
       "      <td>M</td>\n",
       "      <td>1997-01-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Afton Hirthe</td>\n",
       "      <td>M</td>\n",
       "      <td>1970-08-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Olinda Wisoky</td>\n",
       "      <td>F</td>\n",
       "      <td>2007-01-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dr. Annmarie Schmitt PhD</td>\n",
       "      <td>M</td>\n",
       "      <td>1995-09-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Octavie DuBuque</td>\n",
       "      <td>M</td>\n",
       "      <td>1989-12-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Augustina Gibson PhD</td>\n",
       "      <td>M</td>\n",
       "      <td>1973-05-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Dr. Eino Schaefer I</td>\n",
       "      <td>F</td>\n",
       "      <td>1980-12-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Dwayne Lynch</td>\n",
       "      <td>M</td>\n",
       "      <td>2013-01-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Pearley Wiza</td>\n",
       "      <td>M</td>\n",
       "      <td>1996-08-25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        name gender   birthdate\n",
       "0              Leslee Corwin      M  1974-02-01\n",
       "1              Orris Kuvalis      M  1997-01-08\n",
       "2               Afton Hirthe      M  1970-08-25\n",
       "3              Olinda Wisoky      F  2007-01-11\n",
       "4   Dr. Annmarie Schmitt PhD      M  1995-09-29\n",
       "..                       ...    ...         ...\n",
       "95           Octavie DuBuque      M  1989-12-27\n",
       "96      Augustina Gibson PhD      M  1973-05-07\n",
       "97       Dr. Eino Schaefer I      F  1980-12-29\n",
       "98              Dwayne Lynch      M  2013-01-10\n",
       "99              Pearley Wiza      M  1996-08-25\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['name', 'gender', 'birthdate']].head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f46b19",
   "metadata": {},
   "source": [
    "Pandas managed to parse all columns accurately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4804e46b",
   "metadata": {},
   "source": [
    "## Inspecting dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fccb06f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name          object\n",
       "gender        object\n",
       "birthdate     object\n",
       "address       object\n",
       "city          object\n",
       "state         object\n",
       "zipcode        int64\n",
       "email         object\n",
       "bio           object\n",
       "job           object\n",
       "start_date    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Schema\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f024cf7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dtype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>birthdate</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>address</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode</th>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>email</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bio</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>job</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start_date</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Dtype\n",
       "name        object\n",
       "gender      object\n",
       "birthdate   object\n",
       "address     object\n",
       "city        object\n",
       "state       object\n",
       "zipcode      int64\n",
       "email       object\n",
       "bio         object\n",
       "job         object\n",
       "start_date  object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DTypes in pd formatting\n",
    "pd.DataFrame(df.dtypes, columns=['Dtype'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a93937d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zipcode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>48102.664000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>28926.117961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>601.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>22455.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>46668.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>72885.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>99877.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            zipcode\n",
       "count    500.000000\n",
       "mean   48102.664000\n",
       "std    28926.117961\n",
       "min      601.000000\n",
       "25%    22455.000000\n",
       "50%    46668.500000\n",
       "75%    72885.000000\n",
       "max    99877.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Column statistics\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "386cf933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe row count:  500\n",
      "Dataframe columns count:  11\n"
     ]
    }
   ],
   "source": [
    "# Dataframe shape\n",
    "rows, cols = df.shape\n",
    "print(\"Dataframe row count: \", rows)\n",
    "print(\"Dataframe columns count: \", cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80ccdd87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name          0\n",
       "gender        0\n",
       "birthdate     0\n",
       "address       0\n",
       "city          0\n",
       "state         0\n",
       "zipcode       0\n",
       "email         0\n",
       "bio           0\n",
       "job           0\n",
       "start_date    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of missing and values in df for each column\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b46bc46",
   "metadata": {},
   "source": [
    "## Transformation\n",
    "\n",
    "### String cleaning\n",
    "The bio field contains text with arbitrary padding, spacing and line breaks. Normalize these values to a space-delimited string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08e72829",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     At aut velit unde minus recusandae molestias. ...\n",
       "1     Corporis non harum doloribus ab provident.\\t A...\n",
       "2     Sed vitae dolorem quae totam sequi fuga odit.\\...\n",
       "3     Nostrum impedit nulla vero ullam ad repudianda...\n",
       "4     Commodi quia facere dolores facere. Sed culpa ...\n",
       "                            ...                        \n",
       "95    Libero minima dolor sit quos occaecati.\\r\\n De...\n",
       "96    Repellendus cupiditate totam non officia.\\r\\n\\...\n",
       "97    Eaque dignissimos iusto praesentium. Velit vol...\n",
       "98    Debitis enim autem beatae unde ad rerum saepe ...\n",
       "99    Eius id laborum sint.\\t           Dolorem enim...\n",
       "Name: bio, Length: 100, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect 'bio' column\n",
    "df['bio'].head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86c41aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 At aut velit unde minus recusandae molestias. Est maxime labore nostrum.\t Vero debitis neque doloremque accusantium incidunt corporis et et.\n",
      "1 Corporis non harum doloribus ab provident.\t Alias autem error id modi saepe. Ut delectus fugit dolores.\r\n",
      "     \n",
      "2 Sed vitae dolorem quae totam sequi fuga odit.\t        Eaque alias quisquam blanditiis veniam. Aut perferendis sint deleniti accusamus quod.\t\n",
      "3 Nostrum impedit nulla vero ullam ad repudiandae. Excepturi praesentium tempore aspernatur ea est.\t Ipsa alias molestiae rerum omnis voluptates ut.\t    \n",
      "4 Commodi quia facere dolores facere. Sed culpa sit quo.\t Exercitationem error aut odio possimus.\n",
      "5 Non omnis fugit molestias.\r\n",
      " Dolor eum et eveniet soluta eum. Placeat sapiente temporibus perspiciatis tempora quae quia.\t\t\n",
      "6 Eius quas expedita ut culpa doloribus.\r\n",
      " Et laboriosam quidem repellendus eveniet a. Nostrum soluta corporis doloremque sint est excepturi quisquam.\t\r\n",
      "\n",
      "7 Optio molestias accusamus quos aut beatae laudantium qui.\t\r\n",
      " Veniam rerum voluptatibus beatae et facere est.\t Pariatur beatae aut quia est laborum placeat.\n",
      "8 Recusandae quod sed provident consequatur. Ad perferendis harum et tenetur vitae.  Ex eos ad tempore quis est tempora delectus.\n",
      "9 Perspiciatis aut autem ea et odit.\t Quo nulla qui nisi quia aut. Modi natus repellat et qui est numquam est.\r\n",
      "\t\n"
     ]
    }
   ],
   "source": [
    "# Print whole lines \n",
    "n = 10\n",
    "\n",
    "for i in range(0,n):\n",
    "    print(i, df['bio'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6467e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize escape characters, padding and spacing with a single space\n",
    "df['bio'] = (df['bio'].str.replace('\\\\[tbnrfsu]', ' ', regex=True)\n",
    "                      .str.replace('\\s+', ' ', regex=True)\n",
    "                      .str.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c0d8e47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     At aut velit unde minus recusandae molestias. ...\n",
       "1     Corporis non harum doloribus ab provident. Ali...\n",
       "2     Sed vitae dolorem quae totam sequi fuga odit. ...\n",
       "3     Nostrum impedit nulla vero ullam ad repudianda...\n",
       "4     Commodi quia facere dolores facere. Sed culpa ...\n",
       "                            ...                        \n",
       "95    Libero minima dolor sit quos occaecati. Delect...\n",
       "96    Repellendus cupiditate totam non officia. Mole...\n",
       "97    Eaque dignissimos iusto praesentium. Velit vol...\n",
       "98    Debitis enim autem beatae unde ad rerum saepe ...\n",
       "99    Eius id laborum sint. Dolorem enim ut non volu...\n",
       "Name: bio, Length: 100, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirm the changes were applied\n",
    "df['bio'].head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51dbdeaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 At aut velit unde minus recusandae molestias. Est maxime labore nostrum. Vero debitis neque doloremque accusantium incidunt corporis et et.\n",
      "1 Corporis non harum doloribus ab provident. Alias autem error id modi saepe. Ut delectus fugit dolores.\n",
      "2 Sed vitae dolorem quae totam sequi fuga odit. Eaque alias quisquam blanditiis veniam. Aut perferendis sint deleniti accusamus quod.\n",
      "3 Nostrum impedit nulla vero ullam ad repudiandae. Excepturi praesentium tempore aspernatur ea est. Ipsa alias molestiae rerum omnis voluptates ut.\n",
      "4 Commodi quia facere dolores facere. Sed culpa sit quo. Exercitationem error aut odio possimus.\n",
      "5 Non omnis fugit molestias. Dolor eum et eveniet soluta eum. Placeat sapiente temporibus perspiciatis tempora quae quia.\n",
      "6 Eius quas expedita ut culpa doloribus. Et laboriosam quidem repellendus eveniet a. Nostrum soluta corporis doloremque sint est excepturi quisquam.\n",
      "7 Optio molestias accusamus quos aut beatae laudantium qui. Veniam rerum voluptatibus beatae et facere est. Pariatur beatae aut quia est laborum placeat.\n",
      "8 Recusandae quod sed provident consequatur. Ad perferendis harum et tenetur vitae. Ex eos ad tempore quis est tempora delectus.\n",
      "9 Perspiciatis aut autem ea et odit. Quo nulla qui nisi quia aut. Modi natus repellat et qui est numquam est.\n"
     ]
    }
   ],
   "source": [
    "# Print whole lines \n",
    "n = 10\n",
    "\n",
    "for i in range(0,n):\n",
    "    print(i, df['bio'][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19ad5b5",
   "metadata": {},
   "source": [
    "### Code swap \n",
    "There is a supplementary CSV in the files folder under `state_abbreviations`. This \"data dictionary\" contains state abbreviations alongside state names. For the state field of the input CSV, replace each state abbreviation with its associated state name from the data dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35765170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1 - Creating state abbrevations dict using pandas\n",
    "abbr_dict = pd.read_csv('state_abbreviations.csv', index_col='state_abbr').to_dict()['state_name']\n",
    "\n",
    "# Replace 'state' col using dictionary (uncomment line to run this option on dataframe)\n",
    "df['state'] = df['state'].map(abbr_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "226149cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2 - Creating state abbrevations dict using csv\n",
    "import csv\n",
    "\n",
    "with open('state_abbreviations.csv', 'r') as f:\n",
    "    next(f) # skip header line\n",
    "    abbr_dict = {key: val for key,val in csv.reader(f)}\n",
    "\n",
    "# Replace 'state' col using dictionary (uncomment line to run this option on dataframe)\n",
    "# df['state'] = df['state'].map(abbr_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8bcaaea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             Kansas\n",
       "1          Tennessee\n",
       "2           Oklahoma\n",
       "3           Nebraska\n",
       "4     North Carolina\n",
       "5       South Dakota\n",
       "6          Minnesota\n",
       "7           Maryland\n",
       "8      New Hampshire\n",
       "9        Connecticut\n",
       "10           Arizona\n",
       "11           Vermont\n",
       "12          Missouri\n",
       "13              Iowa\n",
       "14      North Dakota\n",
       "15             Texas\n",
       "16     West Virginia\n",
       "17          Illinois\n",
       "18         Tennessee\n",
       "19       Mississippi\n",
       "Name: state, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirming results by inspecting 'state' col\n",
    "df['state'].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e67f5a",
   "metadata": {},
   "source": [
    "### Date offset\n",
    "The start_date field contains data in a variety of formats. These may include e.g., \"June 23, 1912\" or \"5/11/1930\" (month, day, year). But not all values are valid dates. Invalid dates may include e.g., \"June 2018\", \"3/06\" (incomplete dates) or even arbitrary natural language. Add a start_date_description field adjacent to the start_date column to filter invalid date values into. Normalize all valid date values in start_date to ISO 8601 (i.e., YYYY-MM-DD)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2482f663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                    10/06\n",
       "1         Voluptatem odio.\n",
       "2     Est sed et suscipit.\n",
       "3                    06/71\n",
       "4                    05/02\n",
       "5                    10/95\n",
       "6           Ea nostrum et.\n",
       "7               10/20/1994\n",
       "8                    09/74\n",
       "9     Quibusdam similique.\n",
       "10              09/21/1977\n",
       "11           December 1999\n",
       "12           July 11, 1995\n",
       "13     Consequuntur rerum.\n",
       "14            October 1973\n",
       "15          September 1998\n",
       "16     Repellat accusamus.\n",
       "17          March 12, 2000\n",
       "18              1999-09-15\n",
       "19              1970-02-19\n",
       "20      September 18, 1988\n",
       "21           Eum adipisci.\n",
       "22                   02/07\n",
       "23               July 1994\n",
       "24     Voluptates tempore.\n",
       "25                   03/80\n",
       "26              1991-07-22\n",
       "27                May 1988\n",
       "28                   10/02\n",
       "29                   11/97\n",
       "30              March 2005\n",
       "31       Et tempore rerum.\n",
       "32    Accusamus quia odit.\n",
       "33      Voluptatibus iste.\n",
       "34              April 2015\n",
       "35            Fugiat quia.\n",
       "36                   04/01\n",
       "37           February 1993\n",
       "38          Sed quo velit.\n",
       "39    Voluptatem quia qui.\n",
       "40     Ut debitis dolores.\n",
       "41      Impedit eum ipsam.\n",
       "42                   05/87\n",
       "43     Unde harum est non.\n",
       "44              2008-03-08\n",
       "45        February 8, 2015\n",
       "46               July 1991\n",
       "47              1977-02-03\n",
       "48       Perferendis odit.\n",
       "49    Accusantium quis in.\n",
       "Name: start_date, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect 'start_date' col\n",
    "df['start_date'].head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3546c2f7",
   "metadata": {},
   "source": [
    "Spotted 3 date formats that are valid.\n",
    " - \"MMMM/DD/YYYY\"\n",
    " - \"YYYY-MM-DD\"\n",
    " - \"MMMM DD, YYYY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30de4829",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create 'sd' col by running to_datetime() with each format on 'start_date' col\n",
    "df['sd'] = pd.to_datetime(df['start_date'], format=\"%m/%d/%Y\", errors='coerce') \\\n",
    "            .fillna(pd.to_datetime(df['start_date'], format=\"%Y-%m-%d\", errors='coerce')) \\\n",
    "            .fillna(pd.to_datetime(df['start_date'], format=\"%B %d, %Y\", errors='coerce'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8b36facb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           NaT\n",
       "1           NaT\n",
       "2           NaT\n",
       "3           NaT\n",
       "4           NaT\n",
       "5           NaT\n",
       "6           NaT\n",
       "7    1994-10-20\n",
       "8           NaT\n",
       "9           NaT\n",
       "10   1977-09-21\n",
       "11          NaT\n",
       "12   1995-07-11\n",
       "13          NaT\n",
       "14          NaT\n",
       "15          NaT\n",
       "16          NaT\n",
       "17   2000-03-12\n",
       "18   1999-09-15\n",
       "19   1970-02-19\n",
       "Name: sd, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect 'sd' col\n",
    "df['sd'].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6efe733c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check number of not NaT records\n",
    "df['sd'].notna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b922b2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 'sd' col to create 'start_date_description' col describing if 'start_date' vals are Valid or Invalid\n",
    "df['start_date_description'] = 'Valid'\n",
    "df.loc[df['sd'].isna(), 'start_date_description'] = 'Invalid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4add5985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "start_date_description\n",
       "Invalid    338\n",
       "Valid      162\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify the number of Valid records in 'start_date_description'\n",
    "df['start_date_description'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "98f7ec9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As per requirements - the 'start_date' column valid values get normalized while invalid remain unchanged. \n",
    "# If it is not what the reviewer had in mind then in 'sd' column invalid values were turned to null \n",
    "df['start_date'] = df['sd'].dt.date.fillna(df['start_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "46c4a1f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_date</th>\n",
       "      <th>start_date_description</th>\n",
       "      <th>sd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10/06</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Voluptatem odio.</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Est sed et suscipit.</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>06/71</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>05/02</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10/95</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ea nostrum et.</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1994-10-20</td>\n",
       "      <td>Valid</td>\n",
       "      <td>1994-10-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>09/74</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Quibusdam similique.</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1977-09-21</td>\n",
       "      <td>Valid</td>\n",
       "      <td>1977-09-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>December 1999</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1995-07-11</td>\n",
       "      <td>Valid</td>\n",
       "      <td>1995-07-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Consequuntur rerum.</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>October 1973</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>September 1998</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Repellat accusamus.</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2000-03-12</td>\n",
       "      <td>Valid</td>\n",
       "      <td>2000-03-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1999-09-15</td>\n",
       "      <td>Valid</td>\n",
       "      <td>1999-09-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1970-02-19</td>\n",
       "      <td>Valid</td>\n",
       "      <td>1970-02-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1988-09-18</td>\n",
       "      <td>Valid</td>\n",
       "      <td>1988-09-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Eum adipisci.</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>02/07</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>July 1994</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Voluptates tempore.</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>03/80</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1991-07-22</td>\n",
       "      <td>Valid</td>\n",
       "      <td>1991-07-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>May 1988</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>10/02</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>11/97</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>March 2005</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Et tempore rerum.</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Accusamus quia odit.</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Voluptatibus iste.</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>April 2015</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Fugiat quia.</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>04/01</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>February 1993</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Sed quo velit.</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Voluptatem quia qui.</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              start_date start_date_description         sd\n",
       "0                  10/06                Invalid        NaT\n",
       "1       Voluptatem odio.                Invalid        NaT\n",
       "2   Est sed et suscipit.                Invalid        NaT\n",
       "3                  06/71                Invalid        NaT\n",
       "4                  05/02                Invalid        NaT\n",
       "5                  10/95                Invalid        NaT\n",
       "6         Ea nostrum et.                Invalid        NaT\n",
       "7             1994-10-20                  Valid 1994-10-20\n",
       "8                  09/74                Invalid        NaT\n",
       "9   Quibusdam similique.                Invalid        NaT\n",
       "10            1977-09-21                  Valid 1977-09-21\n",
       "11         December 1999                Invalid        NaT\n",
       "12            1995-07-11                  Valid 1995-07-11\n",
       "13   Consequuntur rerum.                Invalid        NaT\n",
       "14          October 1973                Invalid        NaT\n",
       "15        September 1998                Invalid        NaT\n",
       "16   Repellat accusamus.                Invalid        NaT\n",
       "17            2000-03-12                  Valid 2000-03-12\n",
       "18            1999-09-15                  Valid 1999-09-15\n",
       "19            1970-02-19                  Valid 1970-02-19\n",
       "20            1988-09-18                  Valid 1988-09-18\n",
       "21         Eum adipisci.                Invalid        NaT\n",
       "22                 02/07                Invalid        NaT\n",
       "23             July 1994                Invalid        NaT\n",
       "24   Voluptates tempore.                Invalid        NaT\n",
       "25                 03/80                Invalid        NaT\n",
       "26            1991-07-22                  Valid 1991-07-22\n",
       "27              May 1988                Invalid        NaT\n",
       "28                 10/02                Invalid        NaT\n",
       "29                 11/97                Invalid        NaT\n",
       "30            March 2005                Invalid        NaT\n",
       "31     Et tempore rerum.                Invalid        NaT\n",
       "32  Accusamus quia odit.                Invalid        NaT\n",
       "33    Voluptatibus iste.                Invalid        NaT\n",
       "34            April 2015                Invalid        NaT\n",
       "35          Fugiat quia.                Invalid        NaT\n",
       "36                 04/01                Invalid        NaT\n",
       "37         February 1993                Invalid        NaT\n",
       "38        Sed quo velit.                Invalid        NaT\n",
       "39  Voluptatem quia qui.                Invalid        NaT"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirming results by inspecting dataframe\n",
    "df[['start_date', 'start_date_description', 'sd']].head(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57bffa4",
   "metadata": {},
   "source": [
    "## QC check\n",
    "Direct checks on processed columns to confirm successful data preparation. Serving the role of sanity check."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb63d22f",
   "metadata": {},
   "source": [
    "### 'bio' column normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "15aff426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QC: bio column normalization - Passed\n"
     ]
    }
   ],
   "source": [
    "# Tests if 'bio' column does not contain \\n', '\\t', '  ', '   '\n",
    "\n",
    "# Number of records in bio col with undesired characters\n",
    "bio_mask = df['bio'].str.contains('\\n|\\t|  |   ')\n",
    "bio_count = df['bio'].where(bio_mask).count()\n",
    "\n",
    "# Check results\n",
    "if bio_count == 0:\n",
    "    bio_check = True\n",
    "    print('QC: bio column normalization - Passed')\n",
    "else:\n",
    "    bio_check = False\n",
    "    print('QC: bio column normalization - FAILED')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fa416f",
   "metadata": {},
   "source": [
    "### 'state' column abbreviation swap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fcf83dc0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QC: state column abbreviation swap - Passed\n"
     ]
    }
   ],
   "source": [
    "# Tests if all 'state' column strings are larger than 2 \n",
    "\n",
    "# Number of records in 'state' col with strings length < 3\n",
    "state_mask = df['state'].str.len() < 3\n",
    "state_count = df['state'].where(state_mask).count()\n",
    "                 \n",
    "# Check results\n",
    "if state_count == 0:\n",
    "    state_check = True\n",
    "    print('QC: state column abbreviation swap - Passed')\n",
    "else:\n",
    "    state_check = False\n",
    "    print('QC: state column abbreviation swap - FAILED')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bd47aa",
   "metadata": {},
   "source": [
    "### date offset\n",
    "Disclaimer:  Hard to verify numerically. All depends whether user defined all valid formats found in raw column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4d8166c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QC: date offset - \"sd\" column is DateType - Passed\n"
     ]
    }
   ],
   "source": [
    "# Tests if 'sd' staging column dtype is datetime64[ns] \n",
    "date_check1 = str(df['sd'].dtypes) == \"datetime64[ns]\"\n",
    "\n",
    "# Check results\n",
    "if date_check1:\n",
    "    print('QC: date offset - \"sd\" column is DateType - Passed')\n",
    "else:\n",
    "    print('QC: date offset - \"sd\" column is DateType - FAILED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b0615c9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QC: date offset - All Valid dates converted to ISO 8601 - Passed\n"
     ]
    }
   ],
   "source": [
    "# Tests if all valid dates found were converted to ISO 8601 'YYYY-MM-DD' standard\n",
    "\n",
    "# Number of records with initial date format described as valid \n",
    "valid_count = (df['start_date_description'] == 'Valid').sum()\n",
    "# Number of records in ISO 8601 format in 'start_date' col\n",
    "isodate_count = pd.to_datetime(df['start_date'], format='ISO8601', errors='coerce').notna().sum()\n",
    "\n",
    "# Check results\n",
    "date_check2 = valid_count == isodate_count\n",
    "if date_check2:\n",
    "    print('QC: date offset - All Valid dates converted to ISO 8601 - Passed')\n",
    "else:\n",
    "    print('QC: date offset - All Valid dates converted to ISO 8601 - FAILED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e6c3b27f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_date</th>\n",
       "      <th>start_date_description</th>\n",
       "      <th>sd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>02/02</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Sed aut suscipit.</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>May 1988</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>2004-01-01</td>\n",
       "      <td>Valid</td>\n",
       "      <td>2004-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>October 1973</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>Est magnam.</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>July 1991</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>Quia in vero.</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>04/72</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>July 2006</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>Porro rerum alias.</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>1998-10-29</td>\n",
       "      <td>Valid</td>\n",
       "      <td>1998-10-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1977-02-03</td>\n",
       "      <td>Valid</td>\n",
       "      <td>1977-02-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Voluptates tempore.</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>1982-10-01</td>\n",
       "      <td>Valid</td>\n",
       "      <td>1982-10-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Quibusdam similique.</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>2013-04-05</td>\n",
       "      <td>Valid</td>\n",
       "      <td>2013-04-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10/06</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>Debitis voluptatem.</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>Ex voluptates in.</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Voluptatibus iste.</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>May 1979</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>2013-12-25</td>\n",
       "      <td>Valid</td>\n",
       "      <td>2013-12-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>Molestiae quis.</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>08/14</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>1990-10-03</td>\n",
       "      <td>Valid</td>\n",
       "      <td>1990-10-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>1988-01-18</td>\n",
       "      <td>Valid</td>\n",
       "      <td>1988-01-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>04/08</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>Dolores officiis.</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2008-02-22</td>\n",
       "      <td>Valid</td>\n",
       "      <td>2008-02-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>1983-02-17</td>\n",
       "      <td>Valid</td>\n",
       "      <td>1983-02-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>07/88</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>09/05</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>November 2002</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>01/75</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Est et deserunt.</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>February 1980</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>Cumque quisquam hic.</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>06/01</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>May 1980</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>Ut eum nostrum.</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>Dignissimos.</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>December 2012</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>03/87</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>Perspiciatis.</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>1984-03-11</td>\n",
       "      <td>Valid</td>\n",
       "      <td>1984-03-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>1976-05-14</td>\n",
       "      <td>Valid</td>\n",
       "      <td>1976-05-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>1996-12-26</td>\n",
       "      <td>Valid</td>\n",
       "      <td>1996-12-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>1996-11-24</td>\n",
       "      <td>Valid</td>\n",
       "      <td>1996-11-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>2004-12-19</td>\n",
       "      <td>Valid</td>\n",
       "      <td>2004-12-19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               start_date start_date_description         sd\n",
       "91                  02/02                Invalid        NaT\n",
       "96      Sed aut suscipit.                Invalid        NaT\n",
       "27               May 1988                Invalid        NaT\n",
       "194            2004-01-01                  Valid 2004-01-01\n",
       "14           October 1973                Invalid        NaT\n",
       "117           Est magnam.                Invalid        NaT\n",
       "46              July 1991                Invalid        NaT\n",
       "264         Quia in vero.                Invalid        NaT\n",
       "62                  04/72                Invalid        NaT\n",
       "278             July 2006                Invalid        NaT\n",
       "439    Porro rerum alias.                Invalid        NaT\n",
       "109            1998-10-29                  Valid 1998-10-29\n",
       "47             1977-02-03                  Valid 1977-02-03\n",
       "24    Voluptates tempore.                Invalid        NaT\n",
       "252            1982-10-01                  Valid 1982-10-01\n",
       "9    Quibusdam similique.                Invalid        NaT\n",
       "290            2013-04-05                  Valid 2013-04-05\n",
       "0                   10/06                Invalid        NaT\n",
       "386   Debitis voluptatem.                Invalid        NaT\n",
       "249     Ex voluptates in.                Invalid        NaT\n",
       "33     Voluptatibus iste.                Invalid        NaT\n",
       "344              May 1979                Invalid        NaT\n",
       "246            2013-12-25                  Valid 2013-12-25\n",
       "479       Molestiae quis.                Invalid        NaT\n",
       "217                 08/14                Invalid        NaT\n",
       "362            1990-10-03                  Valid 1990-10-03\n",
       "210            1988-01-18                  Valid 1988-01-18\n",
       "125                 04/08                Invalid        NaT\n",
       "227     Dolores officiis.                Invalid        NaT\n",
       "95             2008-02-22                  Valid 2008-02-22\n",
       "238            1983-02-17                  Valid 1983-02-17\n",
       "317                 07/88                Invalid        NaT\n",
       "150                 09/05                Invalid        NaT\n",
       "429         November 2002                Invalid        NaT\n",
       "244                 01/75                Invalid        NaT\n",
       "72       Est et deserunt.                Invalid        NaT\n",
       "299         February 1980                Invalid        NaT\n",
       "141  Cumque quisquam hic.                Invalid        NaT\n",
       "428                 06/01                Invalid        NaT\n",
       "179              May 1980                Invalid        NaT\n",
       "374       Ut eum nostrum.                Invalid        NaT\n",
       "350          Dignissimos.                Invalid        NaT\n",
       "398         December 2012                Invalid        NaT\n",
       "459                 03/87                Invalid        NaT\n",
       "102         Perspiciatis.                Invalid        NaT\n",
       "93             1984-03-11                  Valid 1984-03-11\n",
       "165            1976-05-14                  Valid 1976-05-14\n",
       "341            1996-12-26                  Valid 1996-12-26\n",
       "287            1996-11-24                  Valid 1996-11-24\n",
       "443            2004-12-19                  Valid 2004-12-19"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# additional visual check\n",
    "df[['start_date', 'start_date_description','sd']].sample(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6cb28b",
   "metadata": {},
   "source": [
    "### QC results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0bbd0dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QC Results: SUCCESS\n"
     ]
    }
   ],
   "source": [
    "# Print SUCCESS if all checks passed\n",
    "if all((bio_check, state_check, date_check1, date_check2)):\n",
    "    print(\"QC Results: SUCCESS\")\n",
    "else:\n",
    "    print(\"QC Results: FAILURE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30796402",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "67abd603",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>gender</th>\n",
       "      <th>birthdate</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>email</th>\n",
       "      <th>bio</th>\n",
       "      <th>job</th>\n",
       "      <th>start_date</th>\n",
       "      <th>sd</th>\n",
       "      <th>start_date_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Leslee Corwin</td>\n",
       "      <td>M</td>\n",
       "      <td>1974-02-01</td>\n",
       "      <td>4933 Weber Walks</td>\n",
       "      <td>Lake Carey</td>\n",
       "      <td>Kansas</td>\n",
       "      <td>32725</td>\n",
       "      <td>hansen.kennedy@yahoo.com</td>\n",
       "      <td>At aut velit unde minus recusandae molestias. ...</td>\n",
       "      <td>Education administrator</td>\n",
       "      <td>10/06</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Invalid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Orris Kuvalis</td>\n",
       "      <td>M</td>\n",
       "      <td>1997-01-08</td>\n",
       "      <td>092 Kanye Forge</td>\n",
       "      <td>South Doshiamouth</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>8955</td>\n",
       "      <td>nicky.brown@yahoo.com</td>\n",
       "      <td>Corporis non harum doloribus ab provident. Ali...</td>\n",
       "      <td>Industrial buyer</td>\n",
       "      <td>Voluptatem odio.</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Invalid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Afton Hirthe</td>\n",
       "      <td>M</td>\n",
       "      <td>1970-08-25</td>\n",
       "      <td>355 Shaquille Centers Suite 834</td>\n",
       "      <td>Lorriborough</td>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>12027</td>\n",
       "      <td>noelle.gibson@lebsack.biz</td>\n",
       "      <td>Sed vitae dolorem quae totam sequi fuga odit. ...</td>\n",
       "      <td>Multimedia specialist</td>\n",
       "      <td>Est sed et suscipit.</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Invalid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Olinda Wisoky</td>\n",
       "      <td>F</td>\n",
       "      <td>2007-01-11</td>\n",
       "      <td>48328 Rudolph Harbors</td>\n",
       "      <td>Braunport</td>\n",
       "      <td>Nebraska</td>\n",
       "      <td>19620</td>\n",
       "      <td>desirae.ritchie@yahoo.com</td>\n",
       "      <td>Nostrum impedit nulla vero ullam ad repudianda...</td>\n",
       "      <td>Financial controller</td>\n",
       "      <td>06/71</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Invalid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dr. Annmarie Schmitt PhD</td>\n",
       "      <td>M</td>\n",
       "      <td>1995-09-29</td>\n",
       "      <td>47861 Satterfield Meadow Suite 420</td>\n",
       "      <td>Bergstromshire</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>44200</td>\n",
       "      <td>johnson.betsey@yahoo.com</td>\n",
       "      <td>Commodi quia facere dolores facere. Sed culpa ...</td>\n",
       "      <td>Chartered management accountant</td>\n",
       "      <td>05/02</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Invalid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       name gender   birthdate  \\\n",
       "0             Leslee Corwin      M  1974-02-01   \n",
       "1             Orris Kuvalis      M  1997-01-08   \n",
       "2              Afton Hirthe      M  1970-08-25   \n",
       "3             Olinda Wisoky      F  2007-01-11   \n",
       "4  Dr. Annmarie Schmitt PhD      M  1995-09-29   \n",
       "\n",
       "                              address               city           state  \\\n",
       "0                    4933 Weber Walks         Lake Carey          Kansas   \n",
       "1                     092 Kanye Forge  South Doshiamouth       Tennessee   \n",
       "2     355 Shaquille Centers Suite 834       Lorriborough        Oklahoma   \n",
       "3               48328 Rudolph Harbors          Braunport        Nebraska   \n",
       "4  47861 Satterfield Meadow Suite 420     Bergstromshire  North Carolina   \n",
       "\n",
       "   zipcode                      email  \\\n",
       "0    32725   hansen.kennedy@yahoo.com   \n",
       "1     8955      nicky.brown@yahoo.com   \n",
       "2    12027  noelle.gibson@lebsack.biz   \n",
       "3    19620  desirae.ritchie@yahoo.com   \n",
       "4    44200   johnson.betsey@yahoo.com   \n",
       "\n",
       "                                                 bio  \\\n",
       "0  At aut velit unde minus recusandae molestias. ...   \n",
       "1  Corporis non harum doloribus ab provident. Ali...   \n",
       "2  Sed vitae dolorem quae totam sequi fuga odit. ...   \n",
       "3  Nostrum impedit nulla vero ullam ad repudianda...   \n",
       "4  Commodi quia facere dolores facere. Sed culpa ...   \n",
       "\n",
       "                               job            start_date  sd  \\\n",
       "0          Education administrator                 10/06 NaT   \n",
       "1                 Industrial buyer      Voluptatem odio. NaT   \n",
       "2            Multimedia specialist  Est sed et suscipit. NaT   \n",
       "3             Financial controller                 06/71 NaT   \n",
       "4  Chartered management accountant                 05/02 NaT   \n",
       "\n",
       "  start_date_description  \n",
       "0                Invalid  \n",
       "1                Invalid  \n",
       "2                Invalid  \n",
       "3                Invalid  \n",
       "4                Invalid  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d8e1f5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['zipcode'] = df['zipcode'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "29b10a74",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name                              object\n",
       "gender                            object\n",
       "birthdate                         object\n",
       "address                           object\n",
       "city                              object\n",
       "state                             object\n",
       "zipcode                           object\n",
       "email                             object\n",
       "bio                               object\n",
       "job                               object\n",
       "start_date                        object\n",
       "sd                        datetime64[ns]\n",
       "start_date_description            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba2a21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "split(' ') < 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fbf8b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2b5f9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb3715e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['zipcode'] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e16ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "f\"{[:2]}-{2:}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "21564609",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = '32725'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dc7f463f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spol = f\"{s[:2]}-{s[2:]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e82890ed",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'32-725'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b422c281",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['zipcode_pl'] = df['zipcode'].str[:2] + '-' + df['zipcode'].str[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "870b1552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      32-725\n",
       "1       89-55\n",
       "2      12-027\n",
       "3      19-620\n",
       "4      44-200\n",
       "        ...  \n",
       "495    11-320\n",
       "496    39-216\n",
       "497    50-680\n",
       "498    59-506\n",
       "499     49-38\n",
       "Name: zipcode_pl, Length: 500, dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['zipcode_pl']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d60ff6e",
   "metadata": {},
   "source": [
    "## Save "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "309d156f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write enriched dataframe to csv and snappy.parquet\n",
    "output_name_csv = 'enriched.csv'\n",
    "output_name_parquet = 'enriched.snappy.parquet'\n",
    "\n",
    "# uncomment to actually save\n",
    "#df.to_csv(output_name_csv, index=False)\n",
    "#df.to_parquet(output_name_parquet, compression=\"snappy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45edcffb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
